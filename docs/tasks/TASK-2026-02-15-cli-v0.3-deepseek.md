# Task Card

## Metadata

- Task ID: TASK-2026-02-15-cli-v0.3-deepseek
- Owner: Codex
- Date: 2026-02-15
- Priority: High
- Risk level: Medium

## Objective

将 bidagent 接入 DeepSeek 模型用于二次审查判定，形成“规则召回证据 + LLM 语义判定”流程。

## Definition of Done

1. review 阶段可选启用 DeepSeek 审查（CLI 参数控制）。
2. 对每条 requirement 传入要求文本 + 已检索证据，返回结构化判定。
3. LLM 结果写入 findings（含 llm 字段与最终状态）。
4. 提供单元测试覆盖 JSON 解析与 LLM 覆盖逻辑。

## Scope

- In scope:
  - DeepSeek 客户端（OpenAI-compatible chat completions）
  - review 流程接入 LLM 二次判定
  - CLI 参数与 README 更新
- Out of scope:
  - 多模型路由与自动重试策略平台化
  - 长上下文分块问答优化

## Plan

1. 实现 llm.py 与审查判定提示词。
2. 将 pipeline.review 接入可选 LLM 逻辑。
3. 增加测试并进行验证。

## Verification

- Lint/static: N/A（当前未配置 lint）
- Tests: `python -m unittest discover -s tests -v`
- Build/typecheck: `python -m compileall bidagent tests`
- Smoke test: `python -m bidagent --help`

## Change Log

- Files touched:
  - `bidagent/models.py`
  - `bidagent/llm.py`
  - `bidagent/pipeline.py`
  - `bidagent/cli.py`
  - `bidagent/review.py`
  - `README.md`
  - `tests/test_llm_review.py`
  - `docs/tasks/TASK-2026-02-15-cli-v0.3-deepseek.md`
- Key decisions:
  - 采用“规则先召回证据 + DeepSeek 二次判定”架构
  - LLM 仅接收 requirement + top evidence，避免大文档全文送模
  - LLM 判定支持并行执行（`--ai-workers`）
  - LLM 失败时回退到规则结果，避免流程中断
  - 启用 AI 时即便 `--resume` 也会刷新 review 及下游产物
- Tradeoffs:
  - 当前按 requirement 串行调用模型，极大文档下耗时与成本较高
  - 去重和商务过滤仍为启发式规则，仍需后续数据驱动调参

## Handoff

- Summary:
  - 已完成 DeepSeek 接入，可通过 CLI 参数启用 AI 二次审查
  - 已新增 `llm` 字段写入 findings，包含 provider/model/confidence/decision
  - 已完成单元测试与本地 DeepSeek 最小真实调用 smoke
- Remaining risks:
  - 批量 requirement 调用 LLM 会产生可观成本，建议增加限流与预算阈值
  - LLM 输出结构仍可能偶发格式波动，当前通过解析与回退兜底
- Recommended next step:
  - 在真实样本上运行 AI 模式并对比规则模式，评估误报下降幅度
